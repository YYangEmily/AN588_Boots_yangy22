---
title: "yangy22_OriginalHomeworkCode_05"
author: "Emily Yang"
date: "`r Sys.Date()`"
output: 
  prettydoc::html_pretty:
    theme: cayman

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Bootstrapping Standard Errors and CIs for Linear Models.

When we initially discussed the central limit theorem and confidence intervals, we showed how we could use bootstrapping to estimate standard errors and confidence intervals around certain parameter values, like the mean. Using bootstrapping, we could also do the same for estimating standard errors and CIs around regression parameters, such as β coefficients.

## [1] Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

```{r}
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)

n <- lm(data=d, log(HomeRange_km2) ~ log(Body_mass_female_mean)) # set up model
summary(n)

ci <- confint(n, level = 0.95)  # CI of lm()
ci
```
Coefficients are slope = 1.036 and intercept = -9.441.

<!-- PMB: This is great! For some reason, I have been obsessed with manually calculating the cis (?????), not sure why, but thank you for reminding me of the confint() function. -->


## [2] Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.


```{r}
set.seed(0)
library(boot)

#define function to calculate fitted regression coefficients
coef_function <- function(formula, data, indices) {
  d <- d[indices,] #allows boot to select sample
  fit <- lm(formula, data=d) #fit regression model
  return(coef(fit)) #return coefficient estimates of model
}

#perform bootstrapping with 2000 replications
reps <- boot(data=d, statistic=coef_function, R=1000, formula=log(HomeRange_km2) ~ log(Body_mass_female_mean))

#view results of boostrapping
reps
```

<!-- PMB: Okay this is great too. I googled the boot package and wanted to use it, but because we hadn't talked about it in class I didn't use it, and thus, my bootstrapping didn't work. So you have given me confidence to use it! Great function by the way!  -->

## Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

```{r}

boot.ci(reps, type="norm", index=1) #intercept CI
boot.ci(reps, type="norm", index=2) # slope CI
```

<!-- PMB: Another great function I am learning about! -->

## How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?<br>

Standard error of bootstrapping beta coefficients is 0.5925906 and 0.0760274 which is slightly better than standard error from lm() of 0.67293 and 0.08488. <br>

## How does the latter compare to the 95% CI estimated from your entire dataset? <br> 

The bootstrapping CI is intercept of -10.614 to -8.291 and slope of 0.890 to  1.188. The CI of the entire dataset is intercept of -10.7720889 to -8.110374 and slope of 0.8685707 to 1.204292. The CI from bootstrapping is tighter than the CI of the whole dataset. <br>


https://www.statology.org/bootstrapping-in-r/ 

<!-- PMB: Thanks for citing this-- I will definitely take a look. -->


<!-- PMB: I think your homework code is amazing. Well done! Seriously I have no real notes. In fact, I think just looking at your code has mainly helped me with mine haha! If anything, you should try the extra credit because your code is very good and concise. I am very impressed. Good job. -->